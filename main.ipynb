{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from SimEngine.models.embedding import CAMeL, AraBERTv2, MARBERT, FastTextArabicEmbedder, TFIDFEmbedder, EmbeddingInterface\n",
    "from SimEngine.models.ner import Hatmimoha, NERInterface\n",
    "from SimEngine.preprocessing import TFIDFPreprocessor, ArabertPreprocessor, HardPreprocessor\n",
    "from SimEngine.similarity_engine import SimilarityEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/joined_split_by_agency/joined_جامعة الملك سعود.csv')\n",
    "# agency_name = 'معهد الادارة العامة'\n",
    "x1 = df['fc_description'].values[:100]\n",
    "x2 = x1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `SimEngine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from SimEngine.models.embedding import CAMeL, AraBERTv2, MARBERT, FastTextArabicEmbedder, TFIDFEmbedder, EmbeddingInterface, TransformerEmbedder\n",
    "from SimEngine.models.ner import Hatmimoha, NERInterface\n",
    "from SimEngine.preprocessing import TFIDFPreprocessor, ArabertPreprocessor, HardPreprocessor\n",
    "from SimEngine.similarity_engine import SimilarityEngine\n",
    "\n",
    "\n",
    "finetuned_model = TransformerEmbedder(\n",
    "    model='model_finetuned',\n",
    "    tokenizer='model_finetuned',\n",
    "    pooling_strategy='mean'\n",
    ")\n",
    "\n",
    "# Initialize the embedding models\n",
    "embedding = EmbeddingInterface(embedding_model=finetuned_model) \n",
    "\n",
    "# Initialize the similarity engine\n",
    "engine = SimilarityEngine(\n",
    "                          embedding_interface = embedding, # Embedding models to use\n",
    "                          threshold = 0.8, # Min similarity score to consider\n",
    "                          top_k = None, # Return top k similar entires \n",
    "                          )\n",
    "\n",
    "sim_dict = engine.fit(x1 = x1, x2 = x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sim_dict` has those attributes\n",
    "\n",
    "```python\n",
    "    class SimilarityDict:\n",
    "        x1: List[str] # corpus1\n",
    "        x2: List[str] # corpus2\n",
    "        similarity_matrix: csr_matrix # len(corpus1) x len(corpus2) matrix of simialrity scores\n",
    "        similarity_dict: Dict[str, Dict[str, float]] # {corpus1_sentence : { corpus2_sentence : score}}\n",
    "        threshold: Optional[float] # Min similarity score to report\n",
    "        top_k: Optional[int] # Top k corpus2_sentence to report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'سلفه مؤقته خاصة لصيانة السيارات المسترجعة': {'سلفه مؤقته خاصة لصيانة السيارات المسترجعة': 0.99999994,\n",
      "                                               'صيانة السيارات المسترجعة': 0.8302753}}\n",
      "{'صيانة السيارات المسترجعة': {'سلفه مؤقته خاصة لصيانة السيارات المسترجعة': 0.8302753,\n",
      "                              'صيانة السيارات المسترجعة': 1.0000001,\n",
      "                              'قطع غيار السيارات': 0.8117895}}\n",
      "{'تأمين إحتياجات المركز الجامعي للسكر': {'تأمين إحتياجات المركز الجامعي للسكر': 0.99999994}}\n",
      "{'رحلات علميه': {'رحلات علميه': 0.99999946}}\n",
      "{'أحتياجات الكلية الضرورية والمستعجلة': {'أحتياجات الكلية الضرورية والمستعجلة': 1.0000001}}\n",
      "{'تفرغ علمي': {'تفرغ علمي': 1.0}}\n",
      "{'مكافأة مناقشة الرسائل ': {'دعم أبحاث عمادة البحث العلمي': 0.81537986,\n",
      "                            'دعم مركز البحوث': 0.8173649,\n",
      "                            'مستحقات مناقشة رسائل': 0.8034914,\n",
      "                            'مكافأة أعضاء مناقشة رسائل': 0.94366467,\n",
      "                            'مكافأة مناقشة الرسائل ': 1.0000005,\n",
      "                            'مكافاة أعضاء مناقشة الرسائل': 0.9585389}}\n",
      "{'تأمين كساوي': {'تأمين كساوي': 1.0000002,\n",
      "                 'كساوي': 0.9263354,\n",
      "                 'كساوي ': 0.9263354}}\n",
      "{'دعم مركز البحوث': {'دعم أبحاث عمادة البحث العلمي': 0.89307857,\n",
      "                     'دعم الجمعيه': 0.82773656,\n",
      "                     'دعم الجمعيه ': 0.82773656,\n",
      "                     'دعم مركز البحوث': 1.0000005,\n",
      "                     'مشروع تأسيس مركز القياس والتقويم ': 0.812495,\n",
      "                     'مكافأة مناقشة الرسائل ': 0.8173649,\n",
      "                     'مكافاة أعضاء مناقشة الرسائل': 0.80177003}}\n",
      "{'المشاركة في معسكر الحج': {'المشاركة في معسكر الحج': 1.0000001}}\n",
      "{'احتياجات الاداره': {'احتياجات الاداره': 0.99999994,\n",
      "                      'احتياجات الكليه': 0.8068065}}\n",
      "{'ارسال الطرود البريديه': {'ارسال الطرود البريديه': 0.9999998,\n",
      "                           'ارسال طرود بريديه خاصه بالإنتاج العلمي': 0.8203434,\n",
      "                           'طرود بريديه': 0.8185134}}\n",
      "{'دورات توعويه في السلامة الكيميائيه': {'دورات توعويه في السلامة الكيميائيه': 0.99999994}}\n",
      "{'مجلة العلوم الادارية': {'مجلة العلوم': 0.85132647,\n",
      "                          'مجلة العلوم الادارية': 0.9999998,\n",
      "                          'مجلة العلوم التربويه': 0.85077286}}\n",
      "{'مكافأة أعضاء مناقشة رسائل': {'دعم أبحاث عمادة البحث العلمي': 0.8027384,\n",
      "                               'مستحقات مناقشة رسائل': 0.81597614,\n",
      "                               'مكافأة أعضاء مناقشة رسائل': 0.9999995,\n",
      "                               'مكافأة مناقشة الرسائل ': 0.94366467,\n",
      "                               'مكافاة أعضاء مناقشة الرسائل': 0.969375}}\n",
      "{'المشاركه في الحج 0': {'المشاركه في الحج 1440': 0.99999964}}\n",
      "{'الدوريات العلميه العربيه': {'الدوريات العلميه العربيه': 0.9999997}}\n",
      "{'احتياجات الورش التعليميه والمعامل': {'احتياجات الورش التعليميه والمعامل': 0.9999999}}\n",
      "{'تأمين سياره': {'تأمين سياره': 1.0}}\n",
      "{'طرود بريديه': {'ارسال الطرود البريديه': 0.8185134,\n",
      "                 'ارسال طرود بريديه خاصه بالإنتاج العلمي': 0.81197244,\n",
      "                 'طرود بريديه': 1.0}}\n",
      "{'تطوير اجراءات تقييم نواتج التعلم وفعالية التدريس ': {'تطوير اجراءات تقييم نواتج التعلم وفعالية التدريس ': 1.0000002,\n",
      "                                                       'مستلزمات تطوير العملية التعلمية ': 0.8660542}}\n",
      "{'مستلزمات تطوير العملية التعلمية ': {'تطوير اجراءات تقييم نواتج التعلم وفعالية التدريس ': 0.8660542,\n",
      "                                      'مستلزمات تطوير العملية التعلمية ': 0.9999998,\n",
      "                                      'مشروع تأسيس مركز القياس والتقويم ': 0.8467644}}\n",
      "{'صيانة الاجهزة الطبية بكلية العلوم الطبية التطبيقية ': {'صيانة الاجهزة الطبية بكلية العلوم الطبية التطبيقية ': 0.9999997}}\n",
      "{'دعم الجمعيه ': {'دعم الجمعيه': 1.0000001,\n",
      "                  'دعم الجمعيه ': 1.0000001,\n",
      "                  'دعم مركز البحوث': 0.82773656}}\n",
      "{'احتياجات كلية الهندسة بالمزاحميه': {'احتياجات كلية الهندسة بالمزاحميه': 1.0}}\n",
      "{'مستحقات محكمين ': {'مستحقات محكمين ': 0.9999999,\n",
      "                     'مستحقات مناقشة رسائل': 0.80275214}}\n",
      "{'دعم الجمعيه': {'دعم الجمعيه': 1.0000001,\n",
      "                 'دعم الجمعيه ': 1.0000001,\n",
      "                 'دعم مركز البحوث': 0.82773656}}\n",
      "{'التجمع الكشفي العالمي': {'التجمع الكشفي العالمي': 0.99999994}}\n",
      "{'المشاركة في معرض ابداعات عربيه في دبي': {'المشاركة في معرض ابداعات عربيه في دبي': 0.9999998}}\n",
      "{'اصدار وتجديد الاقامات وتأشيرات الخروج والعودة ': {'اصدار وتجديد الاقامات وتأشيرات الخروج والعودة': 0.99999994,\n",
      "                                                    'اصدار وتجديد الاقامات وتأشيرات الخروج والعودة ': 0.99999994}}\n",
      "{'اقامة فعاليات توعوية وتثقيفية ': {'اقامة فعاليات توعوية وتثقيفية ': 1.0}}\n",
      "{'زمالة عالم': {'زمالة عالم': 1.0, 'مجلة العلوم': 0.80346984}}\n",
      "{'احتياجات الكليه': {'احتياجات الاداره': 0.8068065,\n",
      "                     'احتياجات الكليه': 0.99999917,\n",
      "                     'احتياجات عيادات الكليه': 0.9230992,\n",
      "                     'احتياجات كلية التمريض': 0.85793823}}\n",
      "{'مجلة العلوم': {'زمالة عالم': 0.80346984,\n",
      "                 'مجلة العلوم': 1.0000002,\n",
      "                 'مجلة العلوم الادارية': 0.85132647,\n",
      "                 'مجلة العلوم التربويه': 0.8324716}}\n",
      "{'سلفة توفير الاحتياجات الضرورية والعاجلة لمتطلبات المدينة الطبية من مستلزمات وأجهزة تقنية': {'سلفة توفير الاحتياجات الضرورية والعاجلة لمتطلبات المدينة الطبية من مستلزمات وأجهزة تقنية': 0.9999998,\n",
      "                                                                                              'سلفة مستديمة للصرف على مستشفيات المدينة الطبية من تجهيز وتأثيث': 0.8483386}}\n",
      "{'مهرجان المسرح العربي': {'مهرجان المسرح العربي': 1.0000001}}\n",
      "{'قطع غيار السيارات': {'صيانة السيارات الكهربائيه': 0.8179759,\n",
      "                       'صيانة السيارات المسترجعة': 0.8117895,\n",
      "                       'قطع غيار السيارات': 0.9999995}}\n",
      "{'صيانة السيارات الكهربائيه': {'صيانة السيارات الكهربائيه': 1.0000002,\n",
      "                               'قطع غيار السيارات': 0.8179759}}\n",
      "{'صيانة الشاحنات والباصات': {'صيانة الشاحنات والباصات': 0.99999976}}\n",
      "{'برامج رياضيه مجتمعيه': {'برامج رياضيه مجتمعيه': 0.99999964}}\n",
      "{'مكافاة أعضاء مناقشة الرسائل': {'دعم أبحاث عمادة البحث العلمي': 0.8277159,\n",
      "                                 'دعم مركز البحوث': 0.80177003,\n",
      "                                 'مكافأة أعضاء مناقشة رسائل': 0.969375,\n",
      "                                 'مكافأة مناقشة الرسائل ': 0.9585389,\n",
      "                                 'مكافاة أعضاء مناقشة الرسائل': 1.0000002}}\n",
      "{'المؤتمر العالمي الأول للخدمات الطبية  الطارئة': {'المؤتمر العالمي الأول للخدمات الطبية  الطارئة': 0.9999999}}\n",
      "{'احتياجات كلية التمريض': {'احتياجات الكليه': 0.85793823,\n",
      "                           'احتياجات عيادات الكليه': 0.8319185,\n",
      "                           'احتياجات كلية التمريض': 1.0}}\n",
      "{'دعم أبحاث عمادة البحث العلمي': {'دعم أبحاث عمادة البحث العلمي': 0.9999998,\n",
      "                                  'دعم مركز البحوث': 0.89307857,\n",
      "                                  'مكافأة أعضاء مناقشة رسائل': 0.8027384,\n",
      "                                  'مكافأة مناقشة الرسائل ': 0.81537986,\n",
      "                                  'مكافاة أعضاء مناقشة الرسائل': 0.8277159}}\n",
      "{'ارسال طرود بريديه خاصه بالإنتاج العلمي': {'ارسال الطرود البريديه': 0.8203434,\n",
      "                                            'ارسال طرود بريديه خاصه بالإنتاج العلمي': 1.0000001,\n",
      "                                            'طرود بريديه': 0.81197244}}\n",
      "{'صيانة وقطع غيار الكراسي واجهزة التعقيم والاشعة ومعامل ': {'صيانة وقطع غيار الكراسي واجهزة التعقيم والاشعة ومعامل ': 0.99999976}}\n",
      "{'احتياجات عيادات الكليه': {'احتياجات الكليه': 0.9230992,\n",
      "                            'احتياجات عيادات الكليه': 1.0000001,\n",
      "                            'احتياجات كلية التمريض': 0.8319185}}\n",
      "{'اليوم العالمي للغة العربيه': {'اليوم العالمي للغة العربيه': 0.99999994}}\n",
      "{'مستحقات مناقشة رسائل': {'مستحقات محكمين ': 0.80275214,\n",
      "                          'مستحقات مناقشة رسائل': 0.99999976,\n",
      "                          'مكافأة أعضاء مناقشة رسائل': 0.81597614,\n",
      "                          'مكافأة مناقشة الرسائل ': 0.8034914}}\n",
      "{'مركز أبحاث النباتات الطبيه': {'مركز أبحاث النباتات الطبيه': 1.0}}\n",
      "{'كساوي': {'تأمين كساوي': 0.9263354, 'كساوي': 1.0000001, 'كساوي ': 1.0000001}}\n",
      "{'مجلة العلوم التربويه': {'مجلة العلوم': 0.8324716,\n",
      "                          'مجلة العلوم الادارية': 0.85077286,\n",
      "                          'مجلة العلوم التربويه': 0.99999976}}\n",
      "{'سلفة مستديمة للصرف على مستشفيات المدينة الطبية من تجهيز وتأثيث': {'سلفة توفير الاحتياجات الضرورية والعاجلة لمتطلبات المدينة الطبية من مستلزمات وأجهزة تقنية': 0.8483386,\n",
      "                                                                    'سلفة مستديمة للصرف على مستشفيات المدينة الطبية من تجهيز وتأثيث': 0.9999993}}\n",
      "{'اصدار وتجديد الاقامات وتأشيرات الخروج والعودة': {'اصدار وتجديد الاقامات وتأشيرات الخروج والعودة': 0.99999994,\n",
      "                                                   'اصدار وتجديد الاقامات وتأشيرات الخروج والعودة ': 0.99999994}}\n",
      "{'كساوي ': {'تأمين كساوي': 0.9263354, 'كساوي': 1.0000001, 'كساوي ': 1.0000001}}\n",
      "{'مشروع تأسيس مركز القياس والتقويم ': {'دعم مركز البحوث': 0.812495,\n",
      "                                       'مستلزمات تطوير العملية التعلمية ': 0.8467644,\n",
      "                                       'مشروع تأسيس مركز القياس والتقويم ': 0.99999964}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "numbers = [1,2,3,4,5,6,7,8,9,10]\n",
    "for key,value in sim_dict.similarity_dict.items():\n",
    "    #clean key of numbers\n",
    "    for number in numbers:\n",
    "        key = key.replace(str(number), '')\n",
    "    if key:\n",
    "        pprint({key:value})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string operation on non-string array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/waleedalasad/Documents/GitHub/SimEngine/main.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/waleedalasad/Documents/GitHub/SimEngine/main.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m HardPreprocessor()\u001b[39m.\u001b[39;49mtransform(x1)\n",
      "File \u001b[0;32m~/Documents/GitHub/SimEngine/SimEngine/preprocessing.py:45\u001b[0m, in \u001b[0;36mHardPreprocessor.transform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, data: NDArray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDArray:\n\u001b[1;32m     44\u001b[0m     \u001b[39mfor\u001b[39;00m unwanted_word \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWORDS_TO_EXCLUDE:\n\u001b[0;32m---> 45\u001b[0m         data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mchar\u001b[39m.\u001b[39;49mreplace(data, unwanted_word, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/numpy/core/defchararray.py:1279\u001b[0m, in \u001b[0;36mreplace\u001b[0;34m(a, old, new, count)\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_replace_dispatcher)\n\u001b[1;32m   1242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace\u001b[39m(a, old, new, count\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1243\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[39m    For each element in `a`, return a copy of the string with all\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[39m    occurrences of substring `old` replaced by `new`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[39m    array(['The dwash was fresh', 'Thwas was it'], dtype='<U19')\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m     \u001b[39mreturn\u001b[39;00m _to_bytes_or_str_array(\n\u001b[0;32m-> 1279\u001b[0m         _vec_string(a, object_, \u001b[39m'\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m'\u001b[39;49m, [old, new] \u001b[39m+\u001b[39;49m _clean_args(count)), a)\n",
      "\u001b[0;31mTypeError\u001b[0m: string operation on non-string array"
     ]
    }
   ],
   "source": [
    "HardPreprocessor().transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from SimEngine.utils import convert_sim_dict_to_excel\n",
    "convert_sim_dict_to_excel(sim_dict, f'{agency_name}_similarity.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...:  33%|███▎      | 2/6 [00:07<00:15,  3.77s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Non-consecutive added token '<|startoftext|>' found. Should have index 49408 but has index 49406 in saved vocabulary.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/waleedalasad/Documents/GitHub/SimEngine/main.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waleedalasad/Documents/GitHub/SimEngine/main.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m DiffusionPipeline\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waleedalasad/Documents/GitHub/SimEngine/main.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/waleedalasad/Documents/GitHub/SimEngine/main.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pipe \u001b[39m=\u001b[39m DiffusionPipeline\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mSimianLuo/LCM_Dreamshaper_v7\u001b[39;49m\u001b[39m\"\u001b[39;49m, custom_pipeline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlatent_consistency_txt2img\u001b[39;49m\u001b[39m\"\u001b[39;49m, custom_revision\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waleedalasad/Documents/GitHub/SimEngine/main.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# To save GPU memory, torch.float16 can be used, but it may compromise image quality.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/waleedalasad/Documents/GitHub/SimEngine/main.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pipe\u001b[39m.\u001b[39mto(torch_device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m, torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1105\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m passed_class_obj[name]\n\u001b[1;32m   1103\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     \u001b[39m# load sub model\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m load_sub_model(\n\u001b[1;32m   1106\u001b[0m         library_name\u001b[39m=\u001b[39;49mlibrary_name,\n\u001b[1;32m   1107\u001b[0m         class_name\u001b[39m=\u001b[39;49mclass_name,\n\u001b[1;32m   1108\u001b[0m         importable_classes\u001b[39m=\u001b[39;49mimportable_classes,\n\u001b[1;32m   1109\u001b[0m         pipelines\u001b[39m=\u001b[39;49mpipelines,\n\u001b[1;32m   1110\u001b[0m         is_pipeline_module\u001b[39m=\u001b[39;49mis_pipeline_module,\n\u001b[1;32m   1111\u001b[0m         pipeline_class\u001b[39m=\u001b[39;49mpipeline_class,\n\u001b[1;32m   1112\u001b[0m         torch_dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   1113\u001b[0m         provider\u001b[39m=\u001b[39;49mprovider,\n\u001b[1;32m   1114\u001b[0m         sess_options\u001b[39m=\u001b[39;49msess_options,\n\u001b[1;32m   1115\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   1116\u001b[0m         max_memory\u001b[39m=\u001b[39;49mmax_memory,\n\u001b[1;32m   1117\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   1118\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   1119\u001b[0m         model_variants\u001b[39m=\u001b[39;49mmodel_variants,\n\u001b[1;32m   1120\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1121\u001b[0m         from_flax\u001b[39m=\u001b[39;49mfrom_flax,\n\u001b[1;32m   1122\u001b[0m         variant\u001b[39m=\u001b[39;49mvariant,\n\u001b[1;32m   1123\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   1124\u001b[0m         cached_folder\u001b[39m=\u001b[39;49mcached_folder,\n\u001b[1;32m   1125\u001b[0m     )\n\u001b[1;32m   1126\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   1127\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoaded \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m as \u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m from `\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m` subfolder of \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1128\u001b[0m     )\n\u001b[1;32m   1130\u001b[0m init_kwargs[name] \u001b[39m=\u001b[39m loaded_sub_model  \u001b[39m# UNet(...), # DiffusionSchedule(...)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:472\u001b[0m, in \u001b[0;36mload_sub_model\u001b[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39m# check if the module is in a subdirectory\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cached_folder, name)):\n\u001b[0;32m--> 472\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m load_method(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(cached_folder, name), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mloading_kwargs)\n\u001b[1;32m    473\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[39m# else load from the root directory\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     loaded_sub_model \u001b[39m=\u001b[39m load_method(cached_folder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mloading_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1854\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1852\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading file \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m from cache at \u001b[39m\u001b[39m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1854\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_from_pretrained(\n\u001b[1;32m   1855\u001b[0m     resolved_vocab_files,\n\u001b[1;32m   1856\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m   1857\u001b[0m     init_configuration,\n\u001b[1;32m   1858\u001b[0m     \u001b[39m*\u001b[39;49minit_inputs,\n\u001b[1;32m   1859\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1860\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1861\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1862\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   1863\u001b[0m     _is_local\u001b[39m=\u001b[39;49mis_local,\n\u001b[1;32m   1864\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1865\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2066\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2067\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrong index found for \u001b[39m\u001b[39m{\u001b[39;00mtoken\u001b[39m}\u001b[39;00m\u001b[39m: should be \u001b[39m\u001b[39m{\u001b[39;00mtokenizer\u001b[39m.\u001b[39mconvert_tokens_to_ids(token)\u001b[39m}\u001b[39;00m\u001b[39m but found \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2068\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mindex\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2069\u001b[0m     )\n\u001b[1;32m   2070\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_tokenizer_file \u001b[39mand\u001b[39;00m index \u001b[39m!=\u001b[39m current_index:\n\u001b[1;32m   2071\u001b[0m     \u001b[39m# Tokenizer slow: added token cannot already be in the vocabulary so its index needs to be the\u001b[39;00m\n\u001b[1;32m   2072\u001b[0m     \u001b[39m# current length of the tokenizer.\u001b[39;00m\n\u001b[0;32m-> 2073\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2074\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNon-consecutive added token \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtoken\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m found. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShould have index \u001b[39m\u001b[39m{\u001b[39;00mcurrent_index\u001b[39m}\u001b[39;00m\u001b[39m but has index \u001b[39m\u001b[39m{\u001b[39;00mindex\u001b[39m}\u001b[39;00m\u001b[39m in saved vocabulary.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2076\u001b[0m     )\n\u001b[1;32m   2078\u001b[0m is_special \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(token \u001b[39min\u001b[39;00m special_tokens)\n\u001b[1;32m   2079\u001b[0m \u001b[39mif\u001b[39;00m is_last_special \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m is_last_special \u001b[39m==\u001b[39m is_special:\n",
      "\u001b[0;31mValueError\u001b[0m: Non-consecutive added token '<|startoftext|>' found. Should have index 49408 but has index 49406 in saved vocabulary."
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\"SimianLuo/LCM_Dreamshaper_v7\", custom_pipeline=\"latent_consistency_txt2img\", custom_revision=\"main\")\n",
    "\n",
    "# To save GPU memory, torch.float16 can be used, but it may compromise image quality.\n",
    "pipe.to(torch_device=\"mps\", torch_dtype=torch.float32)\n",
    "\n",
    "prompt = \"Self-portrait oil painting, a beautiful cyborg with golden hair, 8k\"\n",
    "\n",
    "# Can be set to 1~50 steps. LCM support fast inference even <= 4 steps. Recommend: 1~8 steps.\n",
    "num_inference_steps = 2\n",
    "\n",
    "images = pipe(prompt=prompt, num_inference_steps=num_inference_steps, guidance_scale=8.0, lcm_origin_steps=50, output_type=\"pil\").images\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
